#!/usr/bin/env python3

"""
IRIS VOICE INPUT - Complete Voice Recognition System v4.2 FIXED

âœ… Ğ“Ğ›ĞĞ’ĞĞ«Ğ• Ğ˜Ğ¡ĞŸĞ ĞĞ’Ğ›Ğ•ĞĞ˜Ğ¯ v4.2:
1. last_vosk_result_time ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğ¢Ğ¡Ğ¯ Ğ½Ğ° ĞšĞĞ–Ğ”ĞĞœ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ (final Ğ¸Ğ»Ğ¸ partial)
2. Pause detector Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾ (1.5s Ğ¿Ğ°ÑƒĞ·Ğ° = ĞºĞ¾Ğ½ĞµÑ† Ñ„Ñ€Ğ°Ğ·Ñ‹)
3. Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ«Ğ’ĞĞ•Ğ¢Ğ¡Ğ¯ ĞºĞ°Ğº is_final=True
4. AI Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ (Ğ½Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµÑ‚ voice)
"""

import os
import sys
import threading
import time
import queue
import json
import logging
from typing import Optional, Callable, List, Dict, Any, Tuple
from dataclasses import dataclass
from enum import Enum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('voice.log', encoding='utf-8')
    ]
)

logger = logging.getLogger('VoiceInput')

# Import voice recognition libraries
try:
    from vosk import Model, KaldiRecognizer, SetLogLevel
    SetLogLevel(-1)
    VOSK_AVAILABLE = True
    logger.info("âœ… Vosk ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
except ImportError:
    VOSK_AVAILABLE = False
    logger.warning("âš ï¸ Vosk Ğ½Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½. pip install vosk")

try:
    import speech_recognition as sr
    SR_AVAILABLE = True
    logger.info("âœ… SpeechRecognition ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
except ImportError:
    SR_AVAILABLE = False
    logger.warning("âš ï¸ SpeechRecognition Ğ½Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½. pip install SpeechRecognition")

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
    logger.info("âœ… PyAudio ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
except ImportError:
    PYAUDIO_AVAILABLE = False
    logger.warning("âš ï¸ PyAudio Ğ½Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½. pip install pyaudio")

try:
    import sounddevice as sd
    SOUNDDEVICE_AVAILABLE = True
except Exception:
    SOUNDDEVICE_AVAILABLE = False
    logger.info("âš ï¸ SoundDevice Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½ (Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ PortAudio)")

# Constants
WAKEWORD_VARIANTS = ['Ğ¸Ñ€Ğ¸Ñ', 'iris', 'Ğ°Ğ¹Ñ€Ğ¸Ñ', 'Ğ¸Ñ€ÑƒÑ', 'Ğ¸Ñ€Ğ¸Ñˆ', 'ai iris']

QUICK_COMMANDS = {
    'ÑÑ‚Ğ¾Ğ¿': 'stop',
    'ÑÑ‚Ğ¾Ğ¿Ğ¿': 'stop',
    'Ğ²Ñ‹Ñ…Ğ¾Ğ´': 'exit',
    'Ğ¿Ğ°ÑƒĞ·Ğ°': 'pause',
    'Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ°Ğ¹': 'resume',
    'Ğ³Ñ€Ğ¾Ğ¼Ñ‡Ğµ': 'volume_up',
    'Ñ‚Ğ¸ÑˆĞµ': 'volume_down',
    'Ğ²Ñ‹Ñ€ÑƒĞ±': 'mute',
    'Ğ²ĞºĞ»ÑÑ‡Ğ¸': 'unmute',
    'Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒ': 'help',
    'ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹': 'commands',
    'ÑÑ‚Ğ°Ñ‚ÑƒÑ': 'stats',
}

# Sentence ending markers
SENTENCE_ENDINGS = ['.', '!', '?', '...']
PAUSE_THRESHOLD = 1.5  # 1.5 ÑĞµĞº Ğ¿Ğ°ÑƒĞ·Ñ‹ = ĞºĞ¾Ğ½ĞµÑ† Ñ„Ñ€Ğ°Ğ·Ñ‹

@dataclass
class RecognitionStats:
    """Statistics for voice recognition"""
    total_phrases: int = 0
    wake_detected: int = 0
    vosk_success: int = 0
    google_success: int = 0
    avg_confidence: float = 0.0
    last_recognition: str = ""
    audio_quality: float = 0.0

@dataclass
class AudioSettings:
    """Audio configuration"""
    sample_rate: int = 16000
    chunk_size: int = 1600
    channels: int = 1
    energy_threshold: int = 3000
    pause_threshold: float = 0.5
    phrase_threshold: float = 0.3
    non_speaking_duration: float = 0.3
    dynamic_threshold: bool = True

class VoiceInput:
    """
    Complete voice input system with Vosk + Google Speech Recognition
    
    âœ… FIXED v4.2:
    - last_vosk_result_time Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ½Ğ° ĞšĞĞ–Ğ”ĞĞœ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğµ
    - Pause detector Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾
    - Ğ’Ñ‚Ğ¾Ñ€Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ
    - AI Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ
    """

    def __init__(
        self,
        wake_word: str = 'Ğ¸Ñ€Ğ¸Ñ',
        sensitivity: float = 0.8,
        mode: str = 'hybrid',
        vosk_model_path: Optional[str] = None,
        audio_device_index: Optional[int] = None,
        sample_rate: int = 16000,
        enable_analytics: bool = True,
        conversation_timeout: float = 30.0,
        tts_interrupt_callback: Optional[Callable[[], None]] = None
    ):
        """Initialize VoiceInput system"""

        print("=" * 60)
        print("[VOICE] Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ²Ğ²Ğ¾Ğ´Ğ° v4.2 FIXED...")
        print("=" * 60)

        # Core settings
        self.wake_word = wake_word.lower()
        self.sensitivity = max(0.1, min(1.0, sensitivity))
        self.mode = mode
        self.audio_device_index = audio_device_index
        self.sample_rate = sample_rate
        self.enable_analytics = enable_analytics
        self.conversation_timeout = conversation_timeout
        self.tts_interrupt_callback = tts_interrupt_callback

        # Audio settings
        self.audio_settings = AudioSettings(
            sample_rate=sample_rate,
            energy_threshold=int(1500 + (3500 - 1500) * (1 - self.sensitivity))
        )

        # State management
        self.is_listening = False
        self.is_active = False
        self.is_calibrating = False
        self.conversation_active = False
        self.is_processing_command = False

        # Timeouts
        self.activation_timeout = conversation_timeout
        self.last_activation_time = 0
        self.last_audio_time = 0
        self.last_speech_time = 0
        self.last_phrase_text = ""
        self.current_partial_phrase = ""
        self.speech_started_time = 0
        self.user_speaking = False

        # âœ… FIXED: last_vosk_result_time ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğ¢Ğ¡Ğ¯ ĞĞ ĞšĞĞ–Ğ”ĞĞœ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ•!
        self.last_vosk_result_time = 0  # Ğ’Ñ€ĞµĞ¼Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ¾Ñ‚ Vosk (final Ğ¸Ğ»Ğ¸ partial)
        self.phrase_finalization_timeout = 1.5  # 1.5s Ğ¿Ğ°ÑƒĞ·Ñ‹ = ĞºĞ¾Ğ½ĞµÑ† Ñ„Ñ€Ğ°Ğ·Ñ‹

        # Command queue and history
        self.command_queue = queue.PriorityQueue()
        self.audio_buffer = queue.Queue()

        # Callbacks
        self.command_callback: Optional[Callable[[str], None]] = None
        self.wake_callback: Optional[Callable[[], None]] = None
        self.error_callback: Optional[Callable[[Exception], None]] = None

        # Recognition history
        self.recognition_history: List[Dict[str, Any]] = []
        self.max_history = 100
        self.stats = RecognitionStats()

        # Duplicate command prevention
        self.last_command = ""
        self.last_command_time = 0
        self.duplicate_timeout = 0.3

        # Vosk setup
        self.vosk_model = None
        self.vosk_recognizer = None
        self._init_vosk(vosk_model_path)

        # Google Speech Recognition setup
        self.sr_recognizer = None
        self._init_google_speech()

        # Audio device setup
        self.audio_stream = None
        self.pyaudio_instance = None
        self._init_audio_device()

        # Threads
        self.listener_thread: Optional[threading.Thread] = None
        self.processor_thread: Optional[threading.Thread] = None
        self.analytics_thread: Optional[threading.Thread] = None
        self.pause_detector_thread: Optional[threading.Thread] = None

        # Print system info
        self._print_system_info()

        print("=" * 60)
        print("[VOICE] âœ… Ğ’ÑĞµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹")
        print(f"[VOICE] â±ï¸ Ğ ĞµĞ¶Ğ¸Ğ¼ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°: {self.conversation_timeout}s (Ñ‚Ğ°Ğ¹Ğ¼ĞµÑ€ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ Ñ€ĞµÑ‡Ğ¸!)")
        print("[VOICE] ğŸ™ï¸ ĞŸÑ€Ğ¸ Ğ²Ğ°ÑˆĞµĞ¹ Ñ€ĞµÑ‡Ğ¸ Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ñ‹Ğ·Ğ²Ğ°Ğ½ TTS interrupt callback")
        print(f"[VOICE] â¸ï¸ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ğ°ÑƒĞ·Ñ‹: {self.phrase_finalization_timeout}s")
        print("=" * 60)

    def _init_vosk(self, model_path: Optional[str] = None):
        """Initialize Vosk model for offline speech recognition"""
        if not VOSK_AVAILABLE:
            logger.warning("[VOICE] Vosk Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½")
            return

        model_paths = [
            model_path,
            'models/vosk-model-ru-0.22',
            'vosk-model-ru-0.22',
            os.path.expanduser('~/.vosk/vosk-model-ru-0.22'),
            '/usr/share/vosk/vosk-model-ru-0.22',
        ]

        for path in model_paths:
            if path and os.path.exists(path):
                try:
                    self.vosk_model = Model(path)
                    self.vosk_recognizer = KaldiRecognizer(self.vosk_model, self.sample_rate)
                    self.vosk_recognizer.SetWords(True)
                    logger.info(f"[VOICE] âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Vosk Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°: {path}")
                    return
                except Exception as e:
                    logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Vosk: {e}")

        logger.warning("[VOICE] Vosk Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")

    def _init_google_speech(self):
        """Initialize Google Speech Recognition"""
        if not SR_AVAILABLE:
            logger.warning("[VOICE] Google Speech Recognition Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½")
            return

        try:
            self.sr_recognizer = sr.Recognizer()
            self.sr_recognizer.pause_threshold = self.audio_settings.pause_threshold
            self.sr_recognizer.phrase_threshold = self.audio_settings.phrase_threshold
            self.sr_recognizer.non_speaking_duration = self.audio_settings.non_speaking_duration
            self.sr_recognizer.energy_threshold = self.audio_settings.energy_threshold
            self.sr_recognizer.dynamic_energy_threshold = self.audio_settings.dynamic_threshold
            logger.info("[VOICE] âœ… SpeechRecognition Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ SpeechRecognition: {e}")

    def _init_audio_device(self):
        """Initialize audio device and list available devices"""
        logger.info("[VOICE] ĞŸĞ¾Ğ¸ÑĞº Ğ°ÑƒĞ´Ğ¸Ğ¾ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²...")

        if not PYAUDIO_AVAILABLE:
            logger.warning("[VOICE] PyAudio Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½")
            return

        try:
            self.pyaudio_instance = pyaudio.PyAudio()
            device_count = self.pyaudio_instance.get_device_count()
            logger.info(f"[VOICE] ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²: {device_count}")

            for i in range(device_count):
                device_info = self.pyaudio_instance.get_device_info_by_index(i)
                if device_info.get('maxInputChannels', 0) > 0:
                    print(f" [{i}] {device_info.get('name')}")

            self.audio_device_index = self.audio_device_index or self.pyaudio_instance.get_default_input_device_info()['index']
            logger.info(f"[VOICE] Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾: {self.audio_device_index}")

        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ PyAudio: {e}")

    def _print_system_info(self):
        """Print system information"""
        print("\n[VOICE] ğŸ“Š Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞĞĞ¯ Ğ˜ĞĞ¤ĞĞ ĞœĞĞ¦Ğ˜Ğ¯")
        print(f" â€¢ Wake word: '{self.wake_word}'")
        print(f" â€¢ Ğ§ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: {self.sensitivity:.1f}")
        print(f" â€¢ Ğ ĞµĞ¶Ğ¸Ğ¼ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ñ: {self.mode}")
        print(f" â€¢ Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ğ´Ğ¸ÑĞºÑ€ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {self.sample_rate} Hz")
        print(f" â€¢ Vosk Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {'âœ…' if VOSK_AVAILABLE else 'âŒ'}")
        print(f" â€¢ Google Speech Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {'âœ…' if SR_AVAILABLE else 'âŒ'}")
        print(f" â€¢ PyAudio Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {'âœ…' if PYAUDIO_AVAILABLE else 'âŒ'}")
        print(f" â€¢ SoundDevice Ğ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: {'âœ…' if SOUNDDEVICE_AVAILABLE else 'âŒ'}")
        print(f" â€¢ ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°: {'âœ…' if self.enable_analytics else 'âŒ'}")

    def check_wakeword(self, text: str, confidence: float = 1.0) -> Tuple[bool, str]:
        """
        Check if wake word is in text with fuzzy matching
        Returns: (is_wake_word, cleaned_text)
        """
        if not text or len(text.strip()) < 2:
            return False, text

        text_lower = text.lower().strip()
        words = text_lower.split()

        # Method 1: Exact substring match
        for variant in WAKEWORD_VARIANTS:
            if variant in text_lower:
                logger.debug(f"[VOICE] Wake word variant found: {variant}")
                return True, text_lower.replace(variant, '', 1).strip()

        # Method 2: Fuzzy matching
        for word in words:
            if len(word) >= 4:
                for variant in WAKEWORD_VARIANTS:
                    if word.startswith(variant[:4]) and len(variant) >= 4:
                        logger.debug(f"[VOICE] Wake word fuzzy match: {word} ~= {variant}")
                        return True, text_lower.replace(word, '', 1).strip()

        # Method 3: Prefix matching
        for variant in WAKEWORD_VARIANTS:
            if text_lower.startswith(variant):
                logger.debug(f"[VOICE] Wake word prefix match: {variant}")
                return True, text_lower[len(variant):].strip()

        # Method 4: Character overlap
        wake_chars = set(self.wake_word)
        for word in words:
            if len(word) >= 3:
                word_chars = set(word)
                overlap = len(wake_chars & word_chars)
                if overlap >= len(wake_chars) * 0.7:
                    logger.debug(f"[VOICE] Wake word fuzzy overlap: {word}")
                    return True, text_lower.replace(word, '', 1).strip()

        return False, text_lower

    def extract_command(self, text: str) -> str:
        """Extract and clean command from text"""
        if not text:
            return ""

        text_lower = text.lower().strip()

        # Check for quick commands
        for cmd_key, cmd_value in QUICK_COMMANDS.items():
            if cmd_key in text_lower:
                return cmd_value

        # Remove wake word if present
        is_wake, cleaned = self.check_wakeword(text_lower)
        if is_wake:
            return cleaned

        return text_lower

    def is_phrase_complete(self, text: str, time_since_last_speech: float) -> bool:
        """
        Determine if phrase is complete
        Returns True if text ends with punctuation OR pause > 1.5s
        """
        # Check for ending punctuation
        for ending in SENTENCE_ENDINGS:
            if text.rstrip().endswith(ending):
                logger.debug(f"[VOICE] Ğ¤Ñ€Ğ°Ğ·Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° (Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ñ): {text}")
                return True

        # Check for pause duration
        if time_since_last_speech > PAUSE_THRESHOLD:
            logger.debug(f"[VOICE] Ğ¤Ñ€Ğ°Ğ·Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° (Ğ¿Ğ°ÑƒĞ·Ğ° {time_since_last_speech:.1f}s): {text}")
            return True

        return False

    def process_recognition(self, text: str, is_final: bool = False):
        """
        âœ… ĞĞ‘Ğ ĞĞ‘ĞĞ¢Ğ˜Ğ¢Ğ¬ Ğ ĞĞ¡ĞŸĞĞ—ĞĞĞĞĞ«Ğ™ Ğ¢Ğ•ĞšĞ¡Ğ¢
        ĞšĞ¾Ğ³Ğ´Ğ° is_final=True â†’ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ command_callback
        """
        if not text or len(text.strip()) < 2:
            return

        # ğŸ™ï¸ ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğœ Ğ¢ĞĞ™ĞœĞ•Ğ  Ğ˜ last_vosk_result_time
        current_time = time.time()
        self.last_speech_time = current_time
        self.last_vosk_result_time = current_time  # âœ… ĞĞ‘ĞĞĞ’Ğ›Ğ¯Ğ•Ğ¢Ğ¡Ğ¯ ĞĞ ĞšĞĞ–Ğ”ĞĞœ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ•!

        # Ğ•ÑĞ»Ğ¸ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ğ±ĞµÑĞµĞ´Ñ‹ - Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ activation_timeout!
        if self.conversation_active:
            self.last_activation_time = current_time
            logger.debug(f"[VOICE] â±ï¸ Ğ¢Ğ°Ğ¹Ğ¼ĞµÑ€ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»Ñ‘Ğ½: {self.conversation_timeout}s")

        # ğŸ™ï¸ Ğ•ÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ - Ğ¿Ñ€ĞµÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ TTS!
        if self.tts_interrupt_callback:
            try:
                logger.info("[VOICE] ğŸ”‡ ĞŸÑ€ĞµÑ€Ñ‹Ğ²Ğ°Ñ TTS (Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ½Ğ°Ñ‡Ğ°Ğ» Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ÑŒ)")
                self.tts_interrupt_callback()
            except Exception as e:
                logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° TTS interrupt: {e}")

        # Filter pure numbers
        text_clean = text.strip()
        parts = text_clean.split()
        all_numbers = all(all(c.isdigit() or c == '.' or c == '-' for c in part) for part in parts)

        if all_numbers and len(parts) > 0:
            logger.debug(f"[VOICE] ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ° Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ°Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: {text_clean}")
            return

        # Update statistics
        self.stats.total_phrases += 1
        self.stats.last_recognition = text

        # Store in history
        self.recognition_history.append({
            'text': text,
            'timestamp': current_time,
            'is_final': is_final
        })

        if len(self.recognition_history) > self.max_history:
            self.recognition_history.pop(0)

        logger.info(f"ğŸŒ [VOICE] Ğ Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ½Ğ¾: '{text}' (final={is_final})")

        # Check for wake word
        is_wake, cleaned_text = self.check_wakeword(text)

        if is_wake:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ğ Ğ•Ğ–Ğ˜Ğœ 1: ĞĞ‘ĞĞĞ Ğ£Ğ–Ğ•Ğ WAKE WORD
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

            if current_time - self.last_activation_time < 1.0:
                logger.debug(f"[VOICE] Ğ”ÑƒĞ±Ğ»ÑŒ wake word, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼")
                return

            self.stats.wake_detected += 1
            logger.info(f"[VOICE] âœ… Wake word Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: '{self.wake_word}'")

            # Activate conversation mode
            self.is_active = True
            self.conversation_active = True
            self.last_activation_time = current_time
            self.last_speech_time = current_time
            self.current_partial_phrase = cleaned_text

            # Call wake callback
            if self.wake_callback:
                try:
                    self.wake_callback()
                except Exception as e:
                    logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° wake callback: {e}")
                    if self.error_callback:
                        self.error_callback(e)

            # Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¿Ğ¾ÑĞ»Ğµ wake word - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ ĞµĞ³Ğ¾ ĞºĞ°Ğº ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ
            if cleaned_text and len(cleaned_text.strip()) > 2:
                self.handle_command(cleaned_text)

        elif self.conversation_active:
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
            # Ğ Ğ•Ğ–Ğ˜Ğœ 2: Ğ Ğ•Ğ–Ğ˜Ğœ Ğ ĞĞ—Ğ“ĞĞ’ĞĞ Ğ
            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

            self.current_partial_phrase = text

            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ Ñ„Ñ€Ğ°Ğ·Ñ‹
            time_since_speech = current_time - self.last_speech_time

            # âœ… Ğ“Ğ›ĞĞ’ĞĞĞ• Ğ£Ğ¡Ğ›ĞĞ’Ğ˜Ğ•: ĞšĞ¾Ğ³Ğ´Ğ° Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ
            if is_final:
                # Ğ¤Ğ ĞĞ—Ğ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµĞ¼ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñƒ!
                self.last_phrase_text = text
                logger.info(f"[VOICE] ğŸ“ ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ñ„Ñ€Ğ°Ğ·Ğ°: '{text}' (is_final=True)")

                # âœ… Ğ’Ğ«Ğ—Ğ«Ğ’ĞĞ•Ğœ HANDLE_COMMAND
                self.handle_command(text)

            else:
                # Still waiting for more input
                logger.debug(f"[VOICE] â³ ĞĞµĞ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ñ„Ñ€Ğ°Ğ·Ğ°: '{text}' (Ğ¶Ğ´Ñƒ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ...)")

    def handle_command(self, command: str):
        """
        âœ… ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ ĞšĞĞœĞĞĞ”Ğ« - Ğ—Ğ´ĞµÑÑŒ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ command_callback!
        """
        if not command:
            return

        # Clean command
        clean_command = command.strip().lower()

        # Remove wake word if still present
        if clean_command.startswith(self.wake_word):
            clean_command = clean_command[len(self.wake_word):].strip()

        if not clean_command or len(clean_command.strip()) < 2:
            return

        # Check for duplicate commands
        current_time = time.time()
        if self.last_command == clean_command and current_time - self.last_command_time < self.duplicate_timeout:
            logger.debug(f"[VOICE] Ğ”ÑƒĞ±Ğ»ÑŒ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼: {clean_command}")
            return

        # Update command history
        self.last_command = clean_command
        self.last_command_time = current_time

        # Log command
        logger.info(f"ğŸ’¬ [VOICE] ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°: '{clean_command}'")

        # Mark as processing
        self.is_processing_command = True

        # âœ… Ğ’Ğ«Ğ—Ğ«Ğ’ĞĞ•Ğœ COMMAND CALLBACK
        if self.command_callback:
            try:
                logger.info(f"[VOICE] ğŸ“¤ Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°Ñ command_callback Ñ: '{clean_command}'")
                self.command_callback(clean_command)
                logger.info(f"[VOICE] âœ… Callback Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½ Ğ´Ğ»Ñ: '{clean_command}'")
            except Exception as e:
                logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° command callback: {e}")
                if self.error_callback:
                    self.error_callback(e)
        else:
            logger.warning(f"[VOICE] âš ï¸ Command callback Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½!")

        self.is_processing_command = False

        # âœ… ĞĞ• Ğ’Ğ«ĞšĞ›Ğ®Ğ§ĞĞ•Ğœ conversation_active!
        # ĞŸĞ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµĞ¼ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ğ¿Ğ¾Ğ´Ñ€ÑĞ´

    def _pause_detector_loop(self):
        """â­ Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¿Ğ°ÑƒĞ·Ñ‹ - Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ process_recognition Ñ is_final=True ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ°ÑƒĞ·Ğ° >= 1.5s"""
        logger.info("[VOICE] â¸ï¸ Pause detector Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½")

        while self.is_listening:
            try:
                current_time = time.time()

                # Ğ•ÑĞ»Ğ¸ Ğ¼Ñ‹ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ° Ğ¸ Ğ±Ñ‹Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Vosk
                if self.conversation_active and self.last_vosk_result_time > 0:
                    time_since_last = current_time - self.last_vosk_result_time

                    # Ğ•ÑĞ»Ğ¸ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾ >= 1.5 ÑĞµĞº Ğ±ĞµĞ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ° Ğ¸ ĞµÑÑ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ Ñ„Ñ€Ğ°Ğ·Ğ°
                    if time_since_last >= self.phrase_finalization_timeout and self.current_partial_phrase:
                        logger.info(f"[VOICE] â¸ï¸ ĞŸĞ°ÑƒĞ·Ğ° Ğ¾Ğ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½Ğ° ({time_since_last:.1f}s) â†’ Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°Ñ is_final=True")

                        # Ğ’Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ process_recognition Ñ is_final=True
                        self.process_recognition(self.current_partial_phrase, is_final=True)

                        # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ±ÑƒÑ„ĞµÑ€
                        self.current_partial_phrase = ""
                        self.last_vosk_result_time = 0

                time.sleep(0.1)  # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ 100ms

            except Exception as e:
                logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° pause detector: {e}")
                time.sleep(0.1)

    def recognize_with_vosk(self, audio_data: bytes) -> Tuple[Optional[str], bool]:
        """
        Recognize speech using Vosk (offline)
        Returns: (text, is_final)
        """
        if not self.vosk_recognizer:
            return None, False

        try:
            if self.vosk_recognizer.AcceptWaveform(audio_data):
                result_json = self.vosk_recognizer.Result()
                result = json.loads(result_json)

                text = result.get('result', [])

                if text:
                    if isinstance(text, str):
                        if text.strip():
                            return text.strip(), True
                    elif isinstance(text, list) and len(text) > 0:
                        parts = []
                        for item in text:
                            extracted = None
                            if isinstance(item, dict):
                                extracted = item.get('conf') or item.get('result') or item.get('text') or item.get('word')
                            elif isinstance(item, str):
                                extracted = item
                            elif isinstance(item, (int, float)):
                                continue

                            if extracted:
                                extracted_str = str(extracted).strip()
                                if extracted_str:
                                    parts.append(extracted_str)

                        if parts:
                            result_text = ' '.join(parts).strip()
                            if result_text and len(result_text) > 1:
                                return result_text, True

                text = result.get('text', '').strip()
                if text and len(text) > 1:
                    return text, True

            # Check partial result
            partial_json = self.vosk_recognizer.PartialResult()
            partial = json.loads(partial_json)
            text = partial.get('partial', '').strip()

            if text and len(text) > 3:
                return text, False

        except json.JSONDecodeError:
            pass
        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Vosk: {e}")

        return None, False

    def recognize_with_google(self, audio_data) -> Optional[str]:
        """Recognize speech using Google Speech Recognition (online fallback)"""
        if not self.sr_recognizer:
            return None

        try:
            text = self.sr_recognizer.recognize_google(audio_data, language='ru-RU')
            return text
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Google Speech: {e}")
            return None

    def listen_loop_vosk(self):
        """Main Vosk listening loop"""
        print("[VOICE] ğŸ¯ VOSK LOOP STARTED")
        logger.info("[VOICE] âœ… ĞŸÑ€Ğ¾ÑĞ»ÑƒÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ 'hybrid'")
        logger.info(f"[VOICE] Ğ—Ğ°Ğ¿ÑƒÑĞº Vosk Ğ¿Ñ€Ğ¾ÑĞ»ÑƒÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ñ... (ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ '{self.wake_word}')")

        if not VOSK_AVAILABLE or not self.vosk_recognizer:
            logger.error("[VOICE] Vosk Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½!")
            return

        if not PYAUDIO_AVAILABLE:
            logger.warning("[VOICE] PyAudio Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½, Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ÑÑÑŒ Ğ½Ğ° Google")
            self.listen_loop_google()
            return

        try:
            p = pyaudio.PyAudio()

            try:
                self.audio_stream = p.open(
                    format=pyaudio.paInt16,
                    channels=self.audio_settings.channels,
                    rate=self.audio_settings.sample_rate,
                    input=True,
                    input_device_index=self.audio_device_index,
                    frames_per_buffer=self.audio_settings.chunk_size
                )

                logger.info("[VOICE] âœ… ĞÑƒĞ´Ğ¸Ğ¾Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚, Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ ÑĞ»ÑƒÑˆĞ°Ñ‚ÑŒ...")

                while self.is_listening:
                    try:
                        audio_data = self.audio_stream.read(self.audio_settings.chunk_size, exception_on_overflow=False)

                        # Recognize with Vosk
                        text, is_final = self.recognize_with_vosk(audio_data)

                        if text:
                            self.process_recognition(text, is_final=is_final)

                        # Check conversation timeout
                        if self.conversation_active:
                            elapsed = time.time() - self.last_activation_time
                            if elapsed > self.activation_timeout:
                                logger.info(f"[VOICE] â±ï¸ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ±ĞµÑĞµĞ´Ñ‹ ({self.activation_timeout}s), Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ°ÑÑÑŒ")
                                self.conversation_active = False
                                self.is_active = False

                    except Exception as e:
                        logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² Vosk loop: {e}")
                        time.sleep(0.1)

            except Exception as e:
                logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Vosk loop: {e}")
                self.fallback_to_google()

            finally:
                if self.audio_stream:
                    self.audio_stream.stop_stream()
                    self.audio_stream.close()
                logger.info("[VOICE] Vosk loop Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Vosk loop: {e}")
            self.fallback_to_google()

    def listen_loop_google(self):
        """Google Speech Recognition listening loop (fallback)"""
        print("[VOICE] ğŸ”„ GOOGLE LOOP STARTED")
        logger.info("[VOICE] Google Speech Recognition...")

        if not SR_AVAILABLE:
            logger.error("[VOICE] SpeechRecognition Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½!")
            return

        try:
            with sr.Microphone(device_index=self.audio_device_index, sample_rate=self.audio_settings.sample_rate) as source:
                logger.info("[VOICE] ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ° Ğ½Ğ° 2 ÑĞµĞº...")
                self.sr_recognizer.adjust_for_ambient_noise(source, duration=2)
                logger.info(f"[VOICE] ĞŸĞ¾Ñ€Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ ÑĞ½ĞµÑ€Ğ³Ğ¸Ğ¸: {self.sr_recognizer.energy_threshold}")

                while self.is_listening:
                    try:
                        audio = self.sr_recognizer.listen(source, timeout=10.0)
                        text = self.recognize_with_google(audio)

                        if text:
                            self.process_recognition(text, is_final=True)

                    except sr.WaitTimeoutError:
                        # Check conversation timeout
                        if self.conversation_active:
                            elapsed = time.time() - self.last_activation_time
                            if elapsed > self.activation_timeout:
                                logger.info(f"[VOICE] â±ï¸ Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚ Ğ±ĞµÑĞµĞ´Ñ‹ ({self.activation_timeout}s), Ğ²Ñ‹ĞºĞ»ÑÑ‡Ğ°ÑÑÑŒ")
                                self.conversation_active = False
                                self.is_active = False
                        continue

                    except Exception as e:
                        logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Google loop: {e}")
                        time.sleep(0.5)

        except OSError as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°: {e}")
            self.fallback_to_simple()

        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Google loop: {e}")
            self.fallback_to_simple()

        finally:
            logger.info("[VOICE] Google loop Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

    def listen_loop_simple(self):
        """Simple input loop for testing"""
        print("[VOICE] ğŸ“ SIMPLE LOOP STARTED")
        logger.info(f"[VOICE] Simple Ñ€ĞµĞ¶Ğ¸Ğ¼. Ğ¡ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ '{self.wake_word}'")

        while self.is_listening:
            try:
                user_input = input().strip().lower()
                if user_input:
                    self.process_recognition(user_input, is_final=True)
            except EOFError:
                break
            except KeyboardInterrupt:
                break
            except Exception as e:
                logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° Simple loop: {e}")

    def fallback_to_google(self):
        """Fallback from Vosk to Google"""
        logger.warning("[VOICE] Fallback to Google Speech")
        self.mode = 'google'
        if self.is_listening:
            self.listen_loop_google()

    def fallback_to_simple(self):
        """Fallback to simple input mode"""
        logger.warning("[VOICE] Fallback to Simple mode")
        self.mode = 'simple'
        if self.is_listening:
            self.listen_loop_simple()

    def calibrate_microphone(self):
        """Calibrate microphone for better recognition"""
        if self.is_calibrating:
            return

        self.is_calibrating = True
        logger.info("[VOICE] ĞšĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ° Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°...")

        try:
            if self.sr_recognizer:
                with sr.Microphone(device_index=self.audio_device_index) as source:
                    logger.info("[VOICE] Ğ¡Ğ»ÑƒÑˆĞ°Ñ Ğ¾ĞºÑ€ÑƒĞ¶Ğ°ÑÑ‰Ğ¸Ğµ Ğ·Ğ²ÑƒĞºĞ¸ Ğ½Ğ° 2 ÑĞµĞº...")
                    self.sr_recognizer.adjust_for_ambient_noise(source, duration=2)
                    logger.info(f"[VOICE] ĞĞ¾Ğ²Ğ¾Ğµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ: {self.sr_recognizer.energy_threshold}")

        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²ĞºĞ¸: {e}")

        finally:
            self.is_calibrating = False

    def set_command_callback(self, callback: Callable[[str], None]):
        """Set callback for voice commands"""
        self.command_callback = callback
        logger.info("[VOICE] âœ… Command callback ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

    def set_wake_callback(self, callback: Callable[[], None]):
        """Set callback for wake word detection"""
        self.wake_callback = callback
        logger.info("[VOICE] âœ… Wake callback ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

    def set_error_callback(self, callback: Callable[[Exception], None]):
        """Set callback for errors"""
        self.error_callback = callback
        logger.info("[VOICE] âœ… Error callback ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

    def set_tts_interrupt_callback(self, callback: Callable[[], None]):
        """Set callback to interrupt TTS when user speaks"""
        self.tts_interrupt_callback = callback
        logger.info("[VOICE] âœ… TTS interrupt callback ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")

    def get_recognition_stats(self) -> Dict[str, Any]:
        """Get recognition statistics"""
        remaining_timeout = 0
        if self.conversation_active:
            remaining_timeout = max(0, self.activation_timeout - (time.time() - self.last_activation_time))

        return {
            'total_phrases': self.stats.total_phrases,
            'wake_detected': self.stats.wake_detected,
            'vosk_success': self.stats.vosk_success,
            'google_success': self.stats.google_success,
            'avg_confidence': self.stats.avg_confidence,
            'last_recognition': self.stats.last_recognition,
            'audio_quality': self.stats.audio_quality,
            'queue_size': self.command_queue.qsize(),
            'conversation_active': self.conversation_active,
            'conversation_timeout_remaining': remaining_timeout
        }

    def save_stats(self, filename: str = 'voice_stats.json'):
        """Save statistics to file"""
        try:
            stats_data = {
                'timestamp': time.time(),
                'stats': self.get_recognition_stats(),
                'history': self.recognition_history[-50:]
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(stats_data, f, indent=2, ensure_ascii=False)

            logger.info(f"[VOICE] Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ°: {filename}")

        except Exception as e:
            logger.error(f"[VOICE] ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {e}")

    def start(self):
        """Start voice input system"""
        if self.is_listening:
            logger.warning("[VOICE] Ğ£Ğ¶Ğµ Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾")
            return

        self.is_listening = True

        # Select listening mode
        if self.mode == 'vosk':
            target = self.listen_loop_vosk
        elif self.mode == 'google':
            target = self.listen_loop_google
        elif self.mode == 'simple':
            target = self.listen_loop_simple
        else:  # hybrid (default)
            target = self.listen_loop_vosk

        # Start listener thread
        self.listener_thread = threading.Thread(
            target=target,
            daemon=True,
            name='VoiceInput-Listener'
        )
        self.listener_thread.start()

        # â­ Start pause detector thread
        self.pause_detector_thread = threading.Thread(
            target=self._pause_detector_loop,
            daemon=True,
            name='VoiceInput-PauseDetector'
        )
        self.pause_detector_thread.start()

        logger.info(f"[VOICE] âœ… Ğ—Ğ°Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ '{self.mode}'")

    def stop(self):
        """Stop voice input system"""
        if not self.is_listening:
            return

        self.is_listening = False
        self.is_active = False
        self.conversation_active = False

        # Wait for thread
        if self.listener_thread and self.listener_thread.is_alive():
            self.listener_thread.join(timeout=2.0)

        logger.info("[VOICE] âœ… ĞŸÑ€Ğ¾ÑĞ»ÑƒÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾")

def create_voice_input(
    wake_word: str = 'Ğ¸Ñ€Ğ¸Ñ',
    sensitivity: float = 0.8,
    mode: str = 'hybrid',
    conversation_timeout: float = 30.0,
    tts_interrupt_callback: Optional[Callable[[], None]] = None,
    **kwargs
) -> VoiceInput:
    """Factory function to create VoiceInput instance"""
    logger.info(f"[VOICE] Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ VoiceInput: wake_word={wake_word}, mode={mode}, timeout={conversation_timeout}s")

    return VoiceInput(
        wake_word=wake_word,
        sensitivity=sensitivity,
        mode=mode,
        conversation_timeout=conversation_timeout,
        tts_interrupt_callback=tts_interrupt_callback,
        **kwargs
    )
